//
//  AudioService.swift
//  GopeTalkie
//
//  Created by Gopenux on 17/07/25.
//

import AVFoundation

final class AudioService: AudioServiceProtocol {
    private let audioEngine = AVAudioEngine()
    private let playbackEngine = AVAudioEngine()
    private let playerNode = AVAudioPlayerNode()
    private var inputNode: AVAudioInputNode?
    
    private var playbackFormat: AVAudioFormat!
    private var socket: WebSocketServiceProtocol?
    private var converter: AVAudioConverter?
    
    init() {
        configureAudioSession()
        setupFormats()
    }
    
    private func configureAudioSession() {
        do {
            let session = AVAudioSession.sharedInstance()
            try session.setCategory(.playAndRecord, mode: .voiceChat, options: [.defaultToSpeaker, .allowBluetooth])
            try session.setPreferredSampleRate(48000)
            try session.setPreferredIOBufferDuration(0.02)
            try session.setActive(true)
            print("üîß Audio session configured: \(session.sampleRate) Hz")
        } catch {
            print("‚ùå Audio session config failed: \(error.localizedDescription)")
        }
    }
    
    private func setupFormats() {
        playbackFormat = AVAudioFormat(commonFormat: .pcmFormatFloat32,
                                       sampleRate: 16000,
                                       channels: 1,
                                       interleaved: true)
    }
    
    func startStreaming(to socket: WebSocketServiceProtocol) {
        self.socket = socket
        inputNode = audioEngine.inputNode
        
        guard let inputNode else {
            print("‚ùå No input node available")
            return
        }
        
        inputNode.removeTap(onBus: 0)
        
        let inputFormat = inputNode.inputFormat(forBus: 0)
        let targetFormat = AVAudioFormat(commonFormat: .pcmFormatInt16,
                                         sampleRate: 16000,
                                         channels: 1,
                                         interleaved: true)!
        
        converter = AVAudioConverter(from: inputFormat, to: targetFormat)
        
        inputNode.installTap(onBus: 0, bufferSize: 1024, format: inputFormat) { [weak self] buffer, _ in
            guard let self = self, let converter = self.converter else { return }
            
            guard let convertedBuffer = AVAudioPCMBuffer(pcmFormat: targetFormat,
                                                         frameCapacity: AVAudioFrameCount(buffer.frameLength)) else {
                print("‚ùå Could not allocate PCM buffer")
                return
            }
            
            var error: NSError?
            let inputBlock: AVAudioConverterInputBlock = { _, outStatus in
                outStatus.pointee = .haveData
                return buffer
            }
            
            let status = converter.convert(to: convertedBuffer, error: &error, withInputFrom: inputBlock)
            
            if status == .haveData {
                let audioData = convertedBuffer.int16ChannelData!.pointee
                let byteCount = Int(convertedBuffer.frameLength) * MemoryLayout<Int16>.stride
                let data = Data(bytes: audioData, count: byteCount)
                self.socket?.send(data: data)
            } else if let error {
                print("‚ùå Conversion error: \(error.localizedDescription)")
            }
        }
        
        do {
            try audioEngine.start()
            print("üéôÔ∏è Audio engine started")
        } catch {
            print("‚ùå Audio engine failed to start: \(error)")
        }
    }
    
    func stopStreaming() {
        inputNode?.removeTap(onBus: 0)
        audioEngine.stop()
        print("üõë Streaming stopped")
    }
    
    func playAudioData(_ data: Data) {
        guard let buffer = int16DataToFloat32PCMBuffer(data: data) else {
            print("‚ùå Failed to convert data to buffer")
            return
        }
        
        if !playbackEngine.attachedNodes.contains(playerNode) {
            playbackEngine.attach(playerNode)
            playbackEngine.connect(playerNode, to: playbackEngine.mainMixerNode, format: playbackFormat)
        }
        
        do {
            if !playbackEngine.isRunning {
                try playbackEngine.start()
            }
            
            if !playerNode.isPlaying {
                playerNode.play()
            }
            
            playerNode.scheduleBuffer(buffer, at: nil, options: .interrupts, completionHandler: nil)
            
            print("üîä Playing audio - frames: \(buffer.frameLength)")
        } catch {
            print("‚ùå Playback engine failed: \(error)")
        }
    }
    
    private func int16DataToFloat32PCMBuffer(data: Data) -> AVAudioPCMBuffer? {
        let sampleCount = data.count / MemoryLayout<Int16>.size
        
        guard let buffer = AVAudioPCMBuffer(pcmFormat: playbackFormat, frameCapacity: AVAudioFrameCount(sampleCount)) else {
            return nil
        }
        
        buffer.frameLength = AVAudioFrameCount(sampleCount)
        let floatChannel = buffer.floatChannelData![0]
        
        data.withUnsafeBytes { (rawBuffer: UnsafeRawBufferPointer) in
            let int16Pointer = rawBuffer.bindMemory(to: Int16.self)
            for i in 0..<sampleCount {
                floatChannel[i] = Float(int16Pointer[i]) / Float(Int16.max)
            }
        }
        
        return buffer
    }
}
